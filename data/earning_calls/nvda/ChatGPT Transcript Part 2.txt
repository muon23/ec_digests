 Now, as a percentage of total data center revenue, data center sales in China remained well below levels seen on the onset of export controls. Absent any change in regulations, we believe that China's shipments will remain roughly at the current percentage. The market in China for data center solutions remains very competitive. We will continue to comply with export controls while serving our customers.
 Networking revenue declined 3% sequentially. Our networking attached to GPU compute systems is robust at over 75%. We are transitioning from small NVLink 8 with InfiniBand to large NVLink 72 with Spectrum X. Spectrum X and NVLink Switch revenue increased and represents a major new growth sector. We expect networking to return to growth in Q1. AI requires a new class of networking. NVIDIA offers NVLink Switch systems for scale-up compute. For scale-out, we offer Quantum InfiniBand for HPC supercomputers and Spectrum X for Ethernet environments. Spectrum X enhances the Ethernet for AI computing and has been a huge success. Microsoft Azure, OCI, CoreWeave, and others are building large AI factories.
 with Spectrum X. The first Stargate data centers will use Spectrum X. Yesterday, Cisco announced integrating Spectrum X into their networking portfolio to help enterprises build AI infrastructure. With its large enterprise footprint and global reach, Cisco will bring NVIDIA Ethernet to every industry. Now moving to gaming and AI PCs. Gaming revenue of $2.5 billion decreased 22% sequentially and 11% year-on-year. Full-year revenue of $11.4 billion increased 9% year-on-year. And demand remained strong throughout the holiday. However, Q4 shipments were impacted by supply constraints. We expect strong sequential growth in Q1 as supply increases. The new GeForce RTX 50 series.
 desktop and laptop GPUs are here. Built for gamers, creators, and developers, they fuse AI and graphics, redefining visual computing. Powered by the Blackwell architecture, 5th generation Tensor cores, and 4th generation RT cores, and featuring up to 3,400 AI tops. These GPUs deliver a 2x performance leap and new AI driven rendering, including neural shaders, digital human technologies, geometry, and lighting. The new VLSS4 boosts frame rates up to 8x with AI driven frame generation, turning one rendered frame into three. It also features the industry's first real-time application of transformer models, packing 2x more parameters and 4x to compute for unprecedented visual fidelity.
 We also announced a wave of GeForce Blackwell laptop GPUs with new NVIDIA Max-Q technology that extends battery life by up to an incredible 40%. These laptops will be available starting in March from the world's top manufacturers. Moving to our professional visualization business. Revenue of $511 million was up 5% sequentially and 10% year-on-year. Full-year revenue of $1.9 billion increased 21% year-on-year. Key industry verticals driving demand include automotive and healthcare. NVIDIA technologies and generative AI are reshaping design, engineering, and simulation workloads. Increasingly, these technologies are being leveraged in leading software platforms from ANSYS, Cadence, and Siemens, fueling demand for NVIDIA RTX workstations. Now moving to automotive.
 Revenue was a record $570 million, up 27% sequentially and up 103% year-on-year. Full-year revenue of $1.7 billion increased 55% year-on-year. Strong growth was driven by the continued ramp in autonomous vehicles, including cars and robo-taxis. At CES, we announced Toyota, the world's largest automaker, will build its next-generation vehicles on NVIDIA Oren, running the safety-certified NVIDIA DRIVE OS. We announced Aurora and Continental will deploy driverless trucks at scale powered by NVIDIA DRIVE 4. Finally, our end-to-end autonomous vehicle platform, NVIDIA DRIVE Hyperion, has passed industry safety assessments by Su Su and Su Ryland, two of the industry's foremost authorities for automotive-grade safety.
 and cybersecurity. NVIDIA is the first AV platform to receive a comprehensive set of third-party assessments. Okay, moving to the rest of the P&L. Gap gross margins was 73%, and non-gap gross margins was 73.5%, down sequentially as expected with our first deliveries of the Blackwell architecture. As discussed last quarter, Blackwell is a customizable AI infrastructure with several different types of NVIDIA-built chips, multiple networking options, and for air and liquid-cooled data center. We exceeded our expectations in Q4 in ramping Blackwell, increasing system availability, providing several configurations to our customers. As Blackwell ramps, we expect gross margins to be in the low 70s.
 Initially, we are focused on expediting the manufacturing of Blackwell systems to meet strong customer demand as they race to build out Blackwell infrastructure. When fully ramped, we have many opportunities to improve the cost and gross margin will improve and return to the mid-70s late this fiscal year. Sequentially, GAAP operating expenses were up 9% and non-GAAP operating expenses were 11%, reflecting higher engineering development costs and higher compute and infrastructure costs for new product introductions. In Q4, we returned $8.1 billion to shareholders in the form of share repurchases and cash dividends. Let me turn to the outlook in the first quarter. Federal revenue is expected to be $43 billion, plus or minus 2%.
 Continuing with its strong demand, we expect a significant ramp of Blackwell in Q1. We expect sequential growth in both data center and gaming. Within data center, we expect sequential growth from both compute and networking. Gap and non-gap gross margins are expected to be 70.6% and 71%, respectively, plus or minus 50 basis points. Gap and non-gap operating expenses are expected to be approximately $5.2 billion and $3.6 billion, respectively. We expect full-year fiscal year 26 operating expenses to grow to be in the mid-30s. Gap and non-gap other incoming expenses are expected to be an income of approximately $400 million. Expecting gains and losses from non-marketable and publicly held equity securities.
 Gap and non-gap tax rates are expected to be 17 percent, plus or minus 1 percent, excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website, including a new financial information AI agent. In closing, let me highlight upcoming events for the financial community. We will be at the TD Cowen Healthcare Conference in Boston on March 3rd, and at the Morgan Stanley Technology, Media, and Telecom Conference in San Francisco on March 5th. Please join us for our annual GATC conference starting Monday, March 17th, in San Jose, California. Denson will deliver a news-packed keynote on March 18th, and we will host a Q&A session for our financial analysts the next day, March 19th. We look forward to seeing you at these events.
 call to discuss the results for our first quarter of fiscal 2026 is scheduled for May 28, 2025. We are going to open up the call operator to questions. If you could start that, that would be great. Thank you. At this time, I would like to remind everyone in order to ask a question, please press star then the number one on your telephone keypad. I also ask that you please limit yourself.
questions, please recue. And your first question comes from C.J. Mews with Cantor Fitzgerald. Please go ahead. Yeah, good afternoon. Thank you for taking the question. I guess for me, Judson, as Tefcon compute and reinforcement learning shows such promise, we're clearly seeing an increase in blurring of the lines between training and inference. What does this mean for the potential future of potentially inference-dedicated clusters? How do you think about the overall impact to NVIDIA and your customers? Thank you. Yeah, I appreciate that, C.J. There are now multiple scaling laws. There's the pre-training scaling law, and that's going to continue to scale because we have multimodality. We have data that came from reasoning that are now used to do pre-training. And then the
 The second is post-training scaling law, using reinforcement learning human feedback, reinforcement learning AI feedback, reinforcement learning verifiable rewards. The amount of computation you use for post-training is actually higher than pre-training. And it's kind of sensible in the sense that you could, while you're using reinforcement learning, generate an enormous amount of synthetic data or synthetically generated tokens. AI models are basically generating tokens to train AI models. And that's post-training. And the third part, this is the part that you mentioned, is test-time compute or reasoning, long thinking, inference scaling. They're all basically the same ideas. And there you have chain of thought, search, the amount of tokens generated.
 that the amount of inference compute needed is already 100 times more than the one-shot examples and the one-shot capabilities of large language models in the beginning. And that's just the beginning.